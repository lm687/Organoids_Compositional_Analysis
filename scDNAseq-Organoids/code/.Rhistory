geom_density_ridges()+
facet_wrap(.~group, ncol=4)+
geom_vline(data = ML_est, aes(xintercept=value, group=group),
#, col=interaction(parameters, L1)))#+facet_wrap(.~interaction(L1,Var2))
col='red')+
geom_vline(aes(xintercept=0),
#, col=interaction(parameters, L1)))#+facet_wrap(.~interaction(L1,Var2))
col='gray', lty='dashed')+
theme(
strip.background = element_blank(),
strip.text.x = element_blank()
)
ggsave(paste0("../../results/assessing_models/zero_recovery_", dataset_generation, "_stan_recoveries_truezero.png"), height = 2.5, width = 5)
## another view of the same data
ggplot(posterior_est,
aes(x=value, y=parameters,
group=interaction(parameters, L1), fill=L1)#, fill=interaction(parameters, L1))
)+
geom_density_ridges()+
facet_wrap(.~L1, ncol=4)+
geom_vline(aes(xintercept=0),
#, col=interaction(parameters, L1)))#+facet_wrap(.~interaction(L1,Var2))
col='gray', lty='dashed')+
theme(
strip.background = element_blank(),
strip.text.x = element_blank()
)
## Trying to find how we could avoid this inflation in type I errors
## looking at the correlation betweeen estimates, to see if it could be a cause
## subsample the data
sapply(1:length(posteriors_truezeros), function(idx_posteriors_truezeros){
pairs(base::subset(python_like_select_colnames(as(posteriors_truezeros[[idx_posteriors_truezeros]]$fit_stan, 'matrix'), 'beta\\[2'),
sample(c(T,F), size = 2000, replace = T, prob = c(0.1, 0.9))))
})
## is the error in zero coefficients larger than for other coefficients?
## plot in which in the x axis are the sorted coefficients, and in the y axis the errors (|est-true|)
pdf(paste0("../../results/TMB/", dataset_generation, "_ordered_betas_and_error.pdf"), height = 3, width = 5)
plot((df_beta_recovery$beta_est_M - df_beta_recovery$beta_true)[order(df_beta_recovery$beta_true, decreasing = F)], type='h',
xlab='Rank of betas', ylab='Error of betas')
dev.off()
pdf(paste0("../../results/TMB/", dataset_generation, "_ordered_betas_and_error_zoomed_in.pdf"), height = 3, width = 5)
plot((df_beta_recovery$beta_est_M - df_beta_recovery$beta_true)[order(df_beta_recovery$beta_true, decreasing = F)], type='h',
xlab='Rank of betas', ylab='Error of betas', ylim=c(-2,2))
dev.off()
#-------------------------------------------------------------------------------------------------#
## Two M runs for some reason
runs_M1 = readRDS("../../data/robjects_cache/tmb_results_simulations/20200625_simulation_runs_M_5c268769-daa7-4418-a41b-08c6ed9cf5d3.RDS")
runs_M2 = readRDS("../../data/robjects_cache/tmb_results_simulations/20200625_simulation_runs_M_970f6533-5025-4eef-a598-956422846ddf.RDS")
all(sapply(sapply(runs_M1, function(i) i$par.fixed), length) == sapply(sapply(runs_M2, function(i) i$par.fixed), length))
plot(sapply(runs_M1, function(i) i$par.fixed) %>% unlist,
sapply(runs_M2, function(i) i$par.fixed) %>% unlist)
#-------------------------------------------------------------------------------------------------#
rm(list = ls())
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
# setwd("~/Documents/PhD/GlobalDA/code/2_inference_TMB/mm_multinomial/")
library(TMB)
library(scales)
library(uuid)
library(ROCR)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(xtable)
library(mvtnorm)
source("../1_create_ROO/roo_functions.R")
source("../2_inference/helper/helper_DA_stan.R") ## for normalise_rw
source("mm_multinomial/helper_functions.R")
source("helper_TMB.R")
uuid = uuid::UUIDgenerate()
re_run_test = FALSE ## use cache
re_make_plots = TRUE
# set.seed(1245)
#-------------------------------------------------------------------------------------------------#
#-------------------------------------------------------------------------------------------------#
# TMB::compile("mm_multinomial/ME_LNM.cpp", "-std=gnu++17")
# dyn.load(dynlib("mm_multinomial/ME_LNM"))
# TMB::compile("mm_multinomial/ME_multinomial.cpp", "-std=gnu++17")
# dyn.load(dynlib("mm_multinomial/ME_multinomial"))
# TMB::compile("mm_multinomial/ME_dirichletmultinomial.cpp", "-std=gnu++17")
# dyn.load(dynlib("mm_multinomial/ME_dirichletmultinomial"))
TMB::compile("mm_multinomial/fullRE_ME_multinomial.cpp")
dyn.load(dynlib("mm_multinomial/fullRE_ME_multinomial"))
TMB::compile("mm_multinomial/fullRE_ME_dirichletmultinomial.cpp")
dyn.load(dynlib("mm_multinomial/fullRE_ME_dirichletmultinomial"))
#-------------------------------------------------------------------------------------------------#
#-------------------------------------------------------------------------------------------------#
##' Which dataset generation to analyse?
##' 20200625: first generation
##' (B) (not run) same as 20200625, but with non-zero intercept for beta
##' GenerationC: trying to create data that resembles better the PCAWG cohort data
dataset_generation='GenerationE'
dataset_generation=20200625
dataset_generation='GenerationD'
dataset_generation='GenerationC'
dataset_generation='GenerationC_norm'
#-------------------------------------------------------------------------------------------------#
#-------------------------------------------------------------------------------------------------#
datasets_files = list.files("../../data/assessing_models_simulation/datasets/", full.names = TRUE)
datasets_files = datasets_files[grep(pattern = dataset_generation, datasets_files)]
datasets = lapply(datasets_files, readRDS)
names(datasets) = gsub(".RDS", "", basename(datasets_files))
DA_bool = ( sapply(datasets, function(i) i$beta_gamma_shape) > 0 )
#-------------------------------------------------------------------------------------------------#
#-------------------------------------------------------------------------------------------------#
if(re_run_test){
runs_M = lapply(datasets_files, function(i)  try(wrapper_run_TMB(i, model = "fullRE_M", typedata = "simulation", simulation = TRUE)))
names(runs_M) = gsub(".RDS", "", basename(datasets_files))
saveRDS(object = runs_M, file = paste0("../../data/robjects_cache/tmb_results_simulations/", dataset_generation, "_simulation_runs_M_", uuid, ".RDS"))
}else{
runs_M_names = list("../../data/robjects_cache/tmb_results_simulations/singleRE_20200625_simulation_runs_M_970f6533-5025-4eef-a598-956422846ddf.RDS",
"../../data/robjects_cache/tmb_results_simulations/GenerationC_simulation_runs_M_9c1d179c-8003-4398-923a-e08df2f4a439.RDS",
"../../data/robjects_cache/tmb_results_simulations/GenerationD_simulation_runs_M_96f86b9d-c9e5-4ce0-bc46-18503a851944.RDS",
"../../data/robjects_cache/tmb_results_simulations/GenerationE_simulation_runs_M_4c8d8557-8369-4c67-871d-ecea7ae2aa30.RDS",
"../../data/robjects_cache/tmb_results_simulations/GenerationC_norm_simulation_runs_M_ba7b1ea0-3ef3-4775-9a58-246e85627503.RDS")
names(runs_M_names) = c(20200625, 'GenerationC', 'GenerationD', 'GenerationE', 'GenerationC_norm')
runs_M = readRDS(runs_M_names[[as.character(dataset_generation)]])
}
if(re_run_test){
runs_DM = lapply(datasets_files, function(i)  try(wrapper_run_TMB(i, model = "fullRE_M", typedata = "simulation", simulation = TRUE)))
names(runs_DM) = gsub(".RDS", "", basename(datasets_files))
saveRDS(object = runs_DM, file = paste0("../../data/robjects_cache/tmb_results_simulations/", dataset_generation, "_simulation_runs_DM_", uuid, ".RDS"))
}else{
runs_DM_names = list("../../data/robjects_cache/tmb_results_simulations/singleRE_20200625_simulation_runs_DM_d8ea36c9-d0ed-4673-b86b-071de763dc65.RDS", #"../../data/robjects_cache/tmb_results_simulations/20200625_simulation_runs_DM_5c268769-daa7-4418-a41b-08c6ed9cf5d3.RDS",
"../../data/robjects_cache/tmb_results_simulations/GenerationC_simulation_runs_DM_9c1d179c-8003-4398-923a-e08df2f4a439.RDS",
"../../data/robjects_cache/tmb_results_simulations/GenerationD_simulation_runs_DM_96f86b9d-c9e5-4ce0-bc46-18503a851944.RDS",
"../../data/robjects_cache/tmb_results_simulations/GenerationE_simulation_runs_DM_4c8d8557-8369-4c67-871d-ecea7ae2aa30.RDS",
"../../data/robjects_cache/tmb_results_simulations/GenerationC_norm_simulation_runs_DM_ba7b1ea0-3ef3-4775-9a58-246e85627503.RDS")
names(runs_DM_names) = c(20200625, 'GenerationC', 'GenerationD', 'GenerationE', 'GenerationC_norm')
runs_DM = readRDS(runs_DM_names[[as.character(dataset_generation)]])
}
runs_DM
## How many failures have there been?
table(sapply(runs_DM, function(i) all(is.na(i$par.fixed))))
idx_to_repeat = 31
idx_to_repeat = 15
(sapply(runs_DM, function(i) all(is.na(i$par.fixed))))[idx_to_repeat]
try(wrapper_run_TMB(datasets_files[[idx_to_repeat]], model = "fullRE_M", typedata = "simulation", simulation = TRUE))
grep('GenerationE_80_200_NA_4_0_dataset', datasets_files)
get_count_object_file(datasets_files[[idx_to_repeat]])$objects_counts@count_matrices_all
if(re_make_plots) createbarplot_object(datasets_files[[idx_to_repeat]])
#-------------------------------------------------------------------------------------------------#
# Keep only good runs
runs_M[sapply(runs_M, function(i) try(give_summary_per_sample(i))) != "Good"] = NA
runs_DM[sapply(runs_DM, function(i) try(give_summary_per_sample(i))) != "Good"] = NA
x# runs_LNM[sapply(runs_LNM, function(i) try(give_summary_per_sample(i))) != "Good"] = NA
#-------------------------------------------------------------------------------------------------#
wrapper_run_ttest_ilr = function(i){
x = readRDS(i)
x = x[[1]]@count_matrices_all
props = sapply(x, normalise_rw, simplify = FALSE)
return(Compositional::hotel2T2(x1 = compositions::ilr(props[[1]]), x2 = compositions::ilr(props[[2]]))$pvalue)
}
#-------------------------------------------------------------------------------------------------#
wrapper_run_ttest_ilr = function(i){
x = readRDS(i)
x = x[[1]]@count_matrices_all
props = sapply(x, normalise_rw, simplify = FALSE)
return(Compositional::hotel2T2(x1 = compositions::ilr(props[[1]]), x2 = compositions::ilr(props[[2]]))$pvalue)
}
wrapper_run_ttest_props = function(i){
x = readRDS(i)
x = x[[1]]@count_matrices_all
props = sapply(x, normalise_rw, simplify = FALSE)
return(Compositional::hotel2T2(x1 =props[[1]][,-1], x2 = props[[2]][,-1])$pvalue)
}
runs_ttest_irl = lapply(datasets_files, function(i)  try(wrapper_run_ttest_ilr(i)))
runs_ttest_props = lapply(datasets_files, function(i)  try(wrapper_run_ttest_props(i)))
pvals_ttest_ilr = as.numeric(unlist(runs_ttest_irl))
#-------------------------------------------------------------------------------------------------#
## assess if there was good convergence
sapply(runs_M, typeof)
## check if the names are the same
all(names(runs_M) == names(datasets))
all(names(runs_DM) == names(datasets))
#-------------------------------------------------------------------------------------------------#
pvals_M = as.numeric(sapply(runs_M, function(i) try(wald_TMB_wrapper(i, verbatim=FALSE))))
pvals_DM = as.numeric(sapply(runs_DM, function(i) try(wald_TMB_wrapper(i, verbatim=FALSE))))
#-------------------------------------------------------------------------------------------------#
## adjust p-values
## TO DO
pvals_M_adj = pvals_M#*length(pvals_M)
pvals_DM_adj = pvals_DM#*length(pvals_DM)
# pvals_LNM_adj = pvals_LNM*length(pvals_LNM)
pvals_ttest_ilr_adj = pvals_ttest_ilr#*length(pvals_ttest_ilr)
#-------------------------------------------------------------------------------------------------#
## Basic analysis
## How many are said to be differentially abundant, how many actually are?
sapply(list(M=pvals_M_adj <= 0.05, DM=pvals_DM_adj <= 0.05,
# LNM=pvals_LNM_adj <= 0.05,
ttest=pvals_ttest_ilr_adj <= 0.05, true=DA_bool), table)
## Contingency table
table(DA_bool, M=pvals_M_adj <= 0.05)
table(DA_bool, DM=pvals_DM_adj <= 0.05)
table(DA_bool, LNM=pvals_LNM_adj <= 0.05)
## which datasets are TP, TN, FP and FN?
which_contingency = lapply(list(pvals_M_adj, pvals_DM_adj#, pvals_LNM_adj
), function(i) list(TP = as.vector(which(DA_bool & (i <= 0.05))),
TN = as.vector(which(!DA_bool & (i > 0.05))),
FP = as.vector(which(!DA_bool & (i <= 0.05))),
FN = as.vector(which(DA_bool & (i > 0.05)))))
names(which_contingency) = c('M', 'DM')#, 'LNM')
## It doesn't seem to have to do with the number of patients in the datasets
lapply(which_contingency, function(i) sapply(i, function(j) sapply(j, function(k) datasets[[k]]$n)))
#-------------------------------------------------------------------------------------------------#
## compare estimated betas to actual betas
for(j in which(sapply(runs_M, typeof) %in% c("logical", "character"))){
runs_M[[j]] = list(par.fixed=c(beta=rep(NA, 2*(datasets[[j]]$d-1)))) ## *2 for slope and intercept
}
for(j in which(sapply(runs_DM, typeof) %in% c("logical", "character"))){
runs_DM[[j]] = list(par.fixed=c(beta=rep(NA, 2*(datasets[[j]]$d-1)))) ## *2 for slope and intercept
}
true_slope_dataset = (sapply(datasets, function(i) i$beta[2,]))
inferred_slope_M = sapply(runs_M, function(i) try(select_slope_2(python_like_select_name(i$par.fixed, "beta"), verbatim = FALSE)))
par(mfrow=c(1,1))
plot(unlist(true_slope_dataset),
unlist(inferred_slope_M))
abline(coef = c(0, 1))
runs_M
#-------------------------------------------------------------------------------------------------#
## Analysing the characteristics of the DA datasets according to models
#' (to see if there's anything obsviously wrong about the way that data are generated and that could
#' explain poor accuracy of the tests)
par(mfrow=c(1,1))
boxplot(split(log(pvals_M), DA_bool)) ## p-values are generally lower in the truly-DA class.
## how to the betas look in each group? if they are not too different then simply THE SIMULATION IS DONE WRONG
boxplot(sapply(split(sapply(datasets, function(i) i$beta[2,]), DA_bool), function(j) as.vector(unlist(j))))
plot(sapply(split(sapply(datasets, function(i) i$beta[2,]), DA_bool), function(j) as.vector(unlist(j))))
boxplot(log(.2+sapply(split(sapply(datasets, function(i) i$beta[2,]), DA_bool), function(j) as.vector(unlist(j)))))
# some metric indicating change
metric_change = sapply(datasets, function(i){
sum(abs(normalise_rw(i$W[1:i$n,]) - normalise_rw(i$W[(i$n+1):(2*(i$n)),])))/(i$n*i$d)
})
## here it shows that the "DA_bool" doesn't really correlate with how much of an effect there is
par(mfrow=c(1,2))
plot(metric_change, pvals_M_adj <= 0.05, col=(1+as.numeric(DA_bool)), pch=9)
plot(metric_change, pvals_DM_adj <= 0.05, col=(1+as.numeric(DA_bool)), pch=9)
#-------------------------------------------------------------------------------------------------#
if(re_make_plots){
pdf(paste0("../../results/TMB/", dataset_generation, "_pvals_simulation.pdf"), height = 3, width = 10)
par(mfrow=c(1,3))
plot(sort(na.omit(pvals_M)), type = "h", main="M")
plot(sort(na.omit(pvals_DM)), type = "h", main='DM')
# plot(sort(na.omit(pvals_LNM)), type = "h", main="LNM")
dev.off()
}
#-------------------------------------------------------------------------------------------------#
# How do the FP datasets look?
lapply(which_contingency, function(i) i$FP)
lapply(which_contingency, function(i) i$FN)
par(mfrow=c(1,2))
## example of a FN in all datasets
sapply(datasets[[6]]$objects_counts@count_matrices_all, function(i) image(t(i)))
createbarplot_ROOSigs(datasets[[6]]$objects_counts, slot = 'count_matrices_all', pre_path = "../../../CDA_in_Cancer/code/")
datasets[[6]]$beta_gamma_shape
datasets[[6]]$beta
matrix(python_like_select_name(runs_M[[6]]$par.fixed, 'beta'), nrow=2)
pvals_DM[[6]]
which_beta_slope = select_slope_2(grep('beta', names(runs_M[[6]]$par.fixed)), verbatim = FALSE)
stat = t(matrix(select_slope_2(python_like_select_name(runs_M[[6]]$par.fixed, 'beta'), verbatim = FALSE))) %*% solve(runs_M[[6]]$cov.fixed[which_beta_slope,which_beta_slope]) %*% matrix(select_slope_2(python_like_select_name(runs_M[[6]]$par.fixed, 'beta'), verbatim = FALSE))
pchisq(stat, 2, lower.tail = FALSE)
## example of a FP in all
sapply(datasets[[3]]$objects_counts@count_matrices_all, function(i) image(t(i)))
createbarplot_ROOSigs(datasets[[3]]$objects_counts, slot = 'count_matrices_all', pre_path = "../../../CDA_in_Cancer/code/")
datasets[[3]]$beta
matrix(python_like_select_name(runs_M[[3]]$par.fixed, 'beta'), nrow=2)
## plotting all datasets truly DA or not DA, to see if the distinction is obvious
plts = sapply(datasets, function(i) createbarplot_ROOSigs(i$objects_counts, slot = 'count_matrices_all', pre_path = "../../../CDA_in_Cancer/code/"))
#-------------------------------------------------------------------------------------------------#
## Remove outlier datasets
if(remove_outliers){
plot(density(sapply(datasets, function(i) max(i$beta[2,]))))
remove_idx_datasets = which(sapply(datasets, function(i) max(i$beta[2,])) > 5)
if(length(remove_idx_datasets) > 0){
## there is some problematic dataset
datasets = datasets[-remove_idx_datasets]
pvals_M_adj = pvals_M_adj[-remove_idx_datasets]
pvals_DM_adj = pvals_DM_adj[-remove_idx_datasets]
pvals_LNM_adj = pvals_LNM_adj[-remove_idx_datasets]
pvals_ttest_ilr_adj = pvals_ttest_ilr_adj[-remove_idx_datasets]
runs_M = runs_M[-remove_idx_datasets]
runs_DM = runs_DM[-remove_idx_datasets]
runs_LNM = runs_LNM[-remove_idx_datasets]
DA_bool = DA_bool[-remove_idx_datasets]
}
}
#-------------------------------------------------------------------------------------------------#
## Remove outlier datasets
remove_outliers=F
if(remove_outliers){
plot(density(sapply(datasets, function(i) max(i$beta[2,]))))
remove_idx_datasets = which(sapply(datasets, function(i) max(i$beta[2,])) > 5)
if(length(remove_idx_datasets) > 0){
## there is some problematic dataset
datasets = datasets[-remove_idx_datasets]
pvals_M_adj = pvals_M_adj[-remove_idx_datasets]
pvals_DM_adj = pvals_DM_adj[-remove_idx_datasets]
pvals_LNM_adj = pvals_LNM_adj[-remove_idx_datasets]
pvals_ttest_ilr_adj = pvals_ttest_ilr_adj[-remove_idx_datasets]
runs_M = runs_M[-remove_idx_datasets]
runs_DM = runs_DM[-remove_idx_datasets]
runs_LNM = runs_LNM[-remove_idx_datasets]
DA_bool = DA_bool[-remove_idx_datasets]
}
}
summarise_DA_detection = function(true, predicted){
## remove NAs
which_na = which(is.na(predicted))
if(length(which_na) > 0){ ## some NA
true = true[-which_na]
predicted = predicted[-which_na]
}
FPs = sum(!true & predicted)/sum(predicted)
TPs = sum(true & predicted)/sum(predicted)
TNs = sum(!true & !predicted)/sum(!predicted)
FNs = sum(true & !predicted)/sum(!predicted)
total_pos = sum(true | predicted)
Power = TPs/total_pos
Sensitivity = TPs / (TPs + FNs)
Specificity = TNs / (TNs + FPs)
pred <- prediction(as.numeric(true), as.numeric(predicted))
AUC = try(performance(pred, "auc")@y.values[[1]])
return(c(FP=FPs, TP=TPs, Power=Power, AUC=AUC, Specificity=Specificity, Sensitivity=Sensitivity))
}
## they are all pretty horrendous in terms of FP
summarise_DA_detection(true = DA_bool, predicted = pvals_M_adj <= 0.05)
summarise_DA_detection(true = DA_bool, predicted = pvals_DM_adj <= 0.05)
summarise_DA_detection(true = DA_bool, predicted = pvals_LNM_adj <= 0.05)
summarise_DA_detection(true = DA_bool, predicted = pvals_ttest_ilr_adj <= 0.05)
all_summary = do.call('rbind', list(M=summarise_DA_detection(true = DA_bool, predicted = pvals_M_adj <= 0.05),
DM=summarise_DA_detection(true = DA_bool, predicted = pvals_DM_adj <= 0.05),
#LNM=summarise_DA_detection(true = DA_bool, predicted = pvals_LNM_adj <= 0.05),
ttest=summarise_DA_detection(true = DA_bool, predicted = pvals_ttest_ilr_adj <= 0.05)))
xtable::xtable(all_summary, digits=c(0,4,4,4,4,4,4))
pvals_M_adj
pvals_DM_adj
pvals_ttest_ilr_adj
xtable::xtable(all_summary, digits=c(0,4,4,4,4,4,4))
table(sapply(datasets, function(i) i$beta_gamma_shape))
splits = lapply(list(DA_bool, pvals_M_adj, pvals_DM_adj, pvals_ttest_ilr_adj), function(vec)
split(vec,f = sapply(datasets, function(i) i$beta_gamma_shape))
)
names(splits) = c('DA_bool', 'pvals_M_adj', 'pvals_DM_adj', 'pvals_ttest_ilr_adj')
all_summary_balanced = lapply(2:length(splits[[1]]), function(comparison_idx){
DA_bool_comparison = unlist(splits$DA_bool[c(1, comparison_idx)])
do.call('rbind', list(M=summarise_DA_detection(true = DA_bool_comparison,
predicted = unlist(splits$pvals_M_adj[c(1, comparison_idx)]) <= 0.05),
# DM=summarise_DA_detection(true = DA_bool_comparison,
#                           predicted =  unlist(splits$pvals_DM_adj[c(1, comparison_idx)]) <= 0.05),
# LNM=summarise_DA_detection(true = DA_bool_comparison,
#                            predicted =  unlist(splits$pvals_LNM_adj[c(1, comparison_idx)]) <= 0.05),
ttest=summarise_DA_detection(true = DA_bool_comparison,
predicted =  unlist(splits$pvals_ttest_ilr_adj[c(1, comparison_idx)]) <= 0.05)))
})
all_summary_balanced
#-------------------------------------------------------------------------------------------------#
## it should be the case that the number of TRUE increases
sapply(splits$pvals_DM_adj, function(i) table(i <= 0.05))
## fraction of false positives in the first group
sapply(splits, function(i) sum(na.omit(i[[1]] <= 0.05)) /(sum(!is.na(i[[1]]))))
## here there should be a negative correlation (higher effect size <=> lower p-value) (which there is to some extend)
par(mfrow=c(1,3))
plot( sapply(datasets, function(i) i$beta_gamma_shape), pvals_M_adj)
plot( sapply(datasets, function(i) i$beta_gamma_shape), pvals_DM_adj)
plot( sapply(datasets, function(i) i$beta_gamma_shape), pvals_LNM_adj)
#-------------------------------------------------------------------------------------------------#
## here there is only the intercept
df_beta_recovery = cbind.data.frame(beta_true = unlist(sapply(datasets, function(i) i$beta[2,])),
idx = rep(1:length(datasets) , unlist(sapply(datasets, function(i) i$d))-1),
d =  rep(unlist(sapply(datasets, function(i) i$d)), unlist(sapply(datasets, function(i) i$d))-1),
n =  rep(unlist(sapply(datasets, function(i) i$n)), unlist(sapply(datasets, function(i) i$d))-1),
beta_gamma_shape =  rep(unlist(sapply(datasets, function(i) i$beta_gamma_shape)), unlist(sapply(datasets, function(i) i$d))-1),
beta_est_M = unlist(sapply(runs_M, function(i) select_slope_2(python_like_select_name(i$par.fixed, "beta"), verbatim = FALSE))),
beta_stderr_M = unlist(sapply(runs_M, give_stderr)),
beta_est_DM = unlist(sapply(runs_DM, function(i) select_slope_2(python_like_select_name(i$par.fixed, "beta"), verbatim = FALSE))),
beta_stderr_DM = unlist(sapply(runs_DM, give_stderr)),
# beta_est_LNM = unlist(sapply(runs_LNM, function(i) select_slope_2(python_like_select_name(i$par.fixed, "beta"), verbatim = FALSE))),
pvals_M_adj=rep(pvals_M_adj, unlist(sapply(datasets, function(i) i$d))-1),
pvals_DM_adj=rep(pvals_DM_adj, unlist(sapply(datasets, function(i) i$d))-1),
# pvals_LNM_adj=rep(pvals_LNM_adj, unlist(sapply(datasets, function(i) i$d))-1)
DA_bool=rep(DA_bool, unlist(sapply(datasets, function(i) i$d))-1),
idx_within_dataset=unlist(sapply(datasets, function(i) 1:(i$d-1))))
df_beta_recovery$bool_zero_true_beta = factor(df_beta_recovery$beta_true == 0, levels=c(TRUE, FALSE))
pairs(df_beta_recovery[,c('pvals_M_adj', 'pvals_DM_adj'#, 'pvals_LNM_adj'
)], main='Pairs plot of p-values')
pairs(df_beta_recovery[,c('beta_est_M', 'beta_est_DM'#, 'beta_est_LNM'
)], main='Pairs plot of betas')
table(na.omit(df_beta_recovery$pvals_M_adj <= 0.05))
runs_M[[1]]
runs_DM[[1]]
runs_DM = lapply(datasets_files, function(i)  try(wrapper_run_TMB(i, model = "fullRE_DM", typedata = "simulation", simulation = TRUE)))
Signature_Compendium_Definitions_v3 <- readRDS("/Users/morril01/Documents/PhD/other_repos/CNSigs_Comp/data/ProjectNewCNSignatures/Signature_Compendium_Definitions_v3.rds")
Signature_Compendium_Definitions_v3
colnames(Signature_Compendium_Definitions_v3)
## plotting the 10X data
rm(list=ls())
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
library(viridis)
library(grid)
library(pheatmap)
library(gridExtra)
offset_x_vec = c('118976org'=70, '23868org'=65, '119148orgb' = 65)
scaling_x_vec = c('118976org'=0.815, '23868org'=0.82, '119148orgb' = 0.82)
position_chrom_labels_vec = c('118976org'=0.93, '23868org'=0.93, '119148orgb' = 0.95)
cellheight_vec = c('118976org'=2.5, '23868org'=4.8, '119148orgb' = 1.1)
cellwidth_vec = c('118976org'=1.6, '23868org'=1.6, '119148orgb' = 1.6)
renaming = c('118976org'='PDO3', '23868org'='PDO2', '119148orgb'='PDO6')
vec_colours = c("#2670af", "#8daecf", "#eaeaea", "#ffd2b6", "#f5b788", "#f39d5f", "#f17e37", "#ee1200", "#b60000", "#7a0e04", "#401004", "#000000")
x = list()
x_basic = list()
idx = 0
idx = idx+1
org_tab = read.csv(paste0("../UID-", org, ".csv"))
org_tab = apply(org_tab, 2, as.numeric)
renaming[org]
org='118976org'
idx = idx+1
org_tab = read.csv(paste0("../UID-", org, ".csv"))
org_tab = apply(org_tab, 2, as.numeric)
renaming[org]
## plotting the 10X data
rm(list=ls())
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
library(viridis)
library(grid)
library(pheatmap)
library(gridExtra)
offset_x_vec = c('118976org'=70, '23868org'=65, '119148orgb' = 65)
scaling_x_vec = c('118976org'=0.815, '23868org'=0.82, '119148orgb' = 0.82)
position_chrom_labels_vec = c('118976org'=0.93, '23868org'=0.93, '119148orgb' = 0.95)
cellheight_vec = c('118976org'=2.5, '23868org'=4.8, '119148orgb' = 1.1)
cellwidth_vec = c('118976org'=1.6, '23868org'=1.6, '119148orgb' = 1.6)
renaming = c('118976org'='PDO3', '23868org'='PDO2', '119148orgb'='PDO6')
vec_colours = c("#2670af", "#8daecf", "#eaeaea", "#ffd2b6", "#f5b788", "#f39d5f", "#f17e37", "#ee1200", "#b60000", "#7a0e04", "#401004", "#000000")
x = list()
x_basic = list()
idx = 0
for(org in c('118976org', '23868org', '119148orgb')){
idx = idx+1
org_tab = read.csv(paste0("../UID-", org, ".csv"))
org_tab = apply(org_tab, 2, as.numeric)
## printing the cells that have been removed
print(org)
print(org_tab[org_tab[,'num_noisy'] != 0,'node_id'])
org_clean = org_tab[org_tab[,1:4][,'num_noisy'] == 0,-(1:4)]
mat_breaks <- c(-Inf, 0:6, seq(8, 14, by=2)) #seq(min(org_clean, na.rm = T), max(org_clean, na.rm = T), length.out = 10)
labels_chroms0 = sapply(colnames(org_clean), function(i) strsplit(i, '[.]')[[1]][1])
keep = !(labels_chroms0 %in% c('X', 'Y'))
org_clean = org_clean[,keep]
labels_chroms0 = labels_chroms0[keep]
labels_chroms = unique(labels_chroms0)
clean_chrom = function(i){
sapply(i, function(j){
if(j %in% c('X', 'Y')){
j
}else{
## autosomal
substr(j, 2, 1000)
}
})
}
offset_x = offset_x_vec[org]
scaling_x = scaling_x_vec[org]
labels_chroms[1:22] = substr(labels_chroms[1:22], 2, 1000)
labels_chroms = cbind.data.frame(labels_chroms,
idx_first=sapply(unique(sapply(colnames(org_clean), function(i) strsplit(i, '[.]')[[1]][1])), function(i) scaling_x*(offset_x + mean(min(which(sapply(colnames(org_clean), function(i) strsplit(i, '[.]')[[1]][1]) == i)),
max(which(sapply(colnames(org_clean), function(i) strsplit(i, '[.]')[[1]][1]) == i))))))
labels_chroms$idx_first_norm =labels_chroms$idx_first/(ncol(org_clean)-4)
annotation_chroms = data.frame(row.names = colnames(org_clean), chrom=clean_chrom(labels_chroms0))
x[[idx]] = pheatmap(org_clean, cluster_rows = FALSE, cluster_cols = FALSE, show_colnames = FALSE,
color             = c("#2670af", "#8daecf", "#eaeaea", "#ffd2b6", "#f5b788", "#f39d5f", "#f17e37", "#ee1200", "#b60000", "#7a0e04", "#401004", "#000000"),
breaks            = mat_breaks, cellheight=cellheight_vec[org],cellwidth=cellwidth_vec[org], annotation_col = annotation_chroms, annotation_legend=F)
if(org == '23868org'){
legend_bool=T
}else{
legend_bool =F
}
x_basic[[idx]] = pheatmap(org_clean, cluster_rows = FALSE, cluster_cols = FALSE, show_colnames = FALSE,
color             = vec_colours,
breaks            = mat_breaks, annotation_col = annotation_chroms, annotation_legend=F,
legend = legend_bool, cellwidth=cellwidth_vec[org], main=renaming[org], annotation_names_col = FALSE)
pdf(paste0("../plots/basicplot_", org, "_nosexchrom.pdf"), width=15)
print(x[[idx]])
grid::grid.text(labels_chroms$labels_chroms,
x=labels_chroms$idx_first_norm,y=position_chrom_labels_vec[org], gp=gpar(fontsize=10))
dev.off()
}
sapply(x_basic, function(i) i[[4]])
grab_legend = x_basic[[2]][[4]]
x_basic_mod = x_basic
x_basic_mod[[2]][[4]] = x_basic_mod[[2]][[4]][,1:4]
grab_legend_mod = grab_legend[,5]
scaling_x_all = 0.81
offset_x_all = 42
labels_chroms = unique(labels_chroms0)
labels_chroms[1:22] = substr(labels_chroms[1:22], 2, 1000)
labels_chroms = cbind.data.frame(labels_chroms,
idx_first=sapply(unique(sapply(colnames(org_clean), function(i) strsplit(i, '[.]')[[1]][1])),
function(i) scaling_x_all*(offset_x_all + mean(min(which(sapply(colnames(org_clean),
function(i) strsplit(i, '[.]')[[1]][1]) == i)),
max(which(sapply(colnames(org_clean), function(i) strsplit(i, '[.]')[[1]][1]) == i))))))
labels_chroms$idx_first_norm =labels_chroms$idx_first/(ncol(org_clean)-4)
pdf(paste0("../plots/basicplot_all_plots_nosexchrom.pdf"), width=15)
grid.arrange(grobs=list(x_basic_mod[[1]][[4]], rectGrob(gp=gpar(col=NA)),
x_basic_mod[[2]][[4]],  grab_legend_mod,
x_basic_mod[[3]][[4]], rectGrob(gp=gpar(col=NA))), ncol=2, widths = c(8/9, 1/9))
grid::grid.text(labels_chroms$labels_chroms,
x=labels_chroms$idx_first_norm,y=0.9505, gp=gpar(fontsize=10))
grid::grid.text(labels_chroms$labels_chroms,
x=labels_chroms$idx_first_norm,y=0.618, gp=gpar(fontsize=10))
grid::grid.text(labels_chroms$labels_chroms,
x=labels_chroms$idx_first_norm,y=0.286, gp=gpar(fontsize=10))
dev.off()
